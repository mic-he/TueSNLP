{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TueSNLP - Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression\n",
    "The assignment and data are available here: https://snlp2018.github.io/assignments.html.\n",
    "The data (already splitted in training and testing sets) is a list of timestamps of tweets, in the UNIX format. The goal of the assignment is to model the distribution of tweets during the hours of a day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "Load the data, convert it into more informative format and count the number of tweets in each hour of each day. The goal of the exercise is to output two `numpy` arrays, one with the hours (0,1,...,23,0,1,...) and the other with the count of tweets in each hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data (\"rt\" mode makes sure we read as text)\n",
    "with gzip.open(\"data/timestamps.train.gz\", \"rt\") as input_f:\n",
    "    timestamps_train_raw = input_f.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1522533600', '1522533600', '1522533602', '1522533603', '1522533603', '1522533604', '1522533604', '1522533604', '1522533605', '1522533606']\n"
     ]
    }
   ],
   "source": [
    "print(timestamps_train_raw[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert the UNIX format with `time.localtime()`; for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time.struct_time(tm_year=2018, tm_mon=4, tm_mday=1, tm_hour=0, tm_min=0, tm_sec=0, tm_wday=6, tm_yday=91, tm_isdst=1)\n",
      "time.struct_time(tm_year=2018, tm_mon=4, tm_mday=1, tm_hour=0, tm_min=0, tm_sec=0, tm_wday=6, tm_yday=91, tm_isdst=1)\n",
      "time.struct_time(tm_year=2018, tm_mon=4, tm_mday=1, tm_hour=0, tm_min=0, tm_sec=2, tm_wday=6, tm_yday=91, tm_isdst=1)\n"
     ]
    }
   ],
   "source": [
    "print(time.localtime(int(timestamps_train_raw[0])))\n",
    "print(time.localtime(int(timestamps_train_raw[1])))\n",
    "print(time.localtime(int(timestamps_train_raw[2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the attribute `hour` might just be what we need. But first, we make sure the tweets in the data are ordered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps_train_sorted = [int(entry) for entry in timestamps_train_raw] # convert to integer\n",
    "timestamps_train_sorted.sort() # sort with ascending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert with localtime and extract hour attribute\n",
    "timestamps_train_converted = [time.localtime(entry) for entry in timestamps_train_sorted]\n",
    "timestamps_train_hours = np.array([entry.tm_hour for entry in timestamps_train_converted])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to count tweets in each hour in each day, so we need more information, i.e. year, month, day as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps_train_keys = [str(entry.tm_year)+\"-\"+str(entry.tm_mon)+\"-\"+str(entry.tm_mday)+\"-\"+str(entry.tm_hour) for entry in timestamps_train_converted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2018-4-1-0', '2018-4-1-0', '2018-4-1-0', '2018-4-1-0', '2018-4-1-0']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamps_train_keys[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = pd.Series(timestamps_train_keys).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-4-29-18    35725\n",
       "2018-4-26-20    34713\n",
       "2018-4-27-20    31984\n",
       "2018-4-19-21    30970\n",
       "2018-4-20-19    28245\n",
       "dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
