{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 7\n",
    "## GermEval 2018 shared task: identification of offensive language\n",
    "\n",
    "GermEval task: https://projects.fzai.h-da.de/iggsa/germeval-2018/\n",
    "\n",
    "Assignment: https://snlp2018.github.io/assignments.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "The goal of Task 1 is to detect offensive language in social media posts in German: tweets have to be classified as either `OFFENSE` or `OTHER`.\n",
    "\n",
    "Data: https://github.com/uds-lsv/GermEval-2018-Data\n",
    "\n",
    "The file `germeval2018.training.txt` is a tab-separated list of labelled tweets; this is the development set to be used in training and tuning of model(s). The file `germeval2018.test.txt` contains the \"gold-standard\" data against which the final model should be (and has been, in the actual shared task) evaluated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The data\n",
    "First of all, let's read and take a quick look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/germeval2018.training.txt\", sep = \"\\t\", encoding = \"utf-8\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@corinnamilborn Liebe Corinna, wir würden dich...</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Martin28a Sie haben ja auch Recht. Unser Twee...</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@ahrens_theo fröhlicher gruß aus der schönsten...</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@dushanwegner Amis hätten alles und jeden gewä...</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@spdde kein verläßlicher Verhandlungspartner. ...</td>\n",
       "      <td>OFFENSE</td>\n",
       "      <td>INSULT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0        1       2\n",
       "0  @corinnamilborn Liebe Corinna, wir würden dich...    OTHER   OTHER\n",
       "1  @Martin28a Sie haben ja auch Recht. Unser Twee...    OTHER   OTHER\n",
       "2  @ahrens_theo fröhlicher gruß aus der schönsten...    OTHER   OTHER\n",
       "3  @dushanwegner Amis hätten alles und jeden gewä...    OTHER   OTHER\n",
       "4  @spdde kein verläßlicher Verhandlungspartner. ...  OFFENSE  INSULT"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe: first column contains tweet and second column the labels `OFFENSE` or `OTHER`; third column contains finer-grained labeling which we are not interesed in at the moment. Let's drop the latter and give the other two columns user-friendly names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.columns[2], axis = 1, inplace = True)\n",
    "df.columns = [\"tweet\", \"category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@corinnamilborn Liebe Corinna, wir würden dich...</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Martin28a Sie haben ja auch Recht. Unser Twee...</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@ahrens_theo fröhlicher gruß aus der schönsten...</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@dushanwegner Amis hätten alles und jeden gewä...</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@spdde kein verläßlicher Verhandlungspartner. ...</td>\n",
       "      <td>OFFENSE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet category\n",
       "0  @corinnamilborn Liebe Corinna, wir würden dich...    OTHER\n",
       "1  @Martin28a Sie haben ja auch Recht. Unser Twee...    OTHER\n",
       "2  @ahrens_theo fröhlicher gruß aus der schönsten...    OTHER\n",
       "3  @dushanwegner Amis hätten alles und jeden gewä...    OTHER\n",
       "4  @spdde kein verläßlicher Verhandlungspartner. ...  OFFENSE"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the data balanced? Let's find out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OFFENSE</th>\n",
       "      <td>1688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OTHER</th>\n",
       "      <td>3321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tweet\n",
       "category       \n",
       "OFFENSE    1688\n",
       "OTHER      3321"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"category\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not quite, there are twice as many tweets labelled as `OTHER` than tweets labelled as `OFFENSE`. Is this a problem? It can be; so: 1) we won't use accuracy but precision and recall metrics and 2) we might need to weight the loss function(s) of our model(s). We'll come back to this later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing\n",
    "\n",
    "What do the tweets look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Steuermehreinnahmen. Wofür? Blöde Frage. Es gibt so viele Löcher, |LBR| die gestopft werden müssen. Hört auf mit Steuergeschenken.', '@bettisweb @dannytastisch Hi, Marktplatz 40213 Düsseldorf um 14 Uhr.', '@X9donernesto @petpanther0 @machtjanix23 @NoHerrman @teite99 @info2099 @lifetrend @ThomasGBauer @SchmiddieMaik @AthinaMala @charlie_silve @willjrosenblatt @feldenfrizz @nasanasal @_macmike @ellibisathide @MD_Franz Kann ich Dir nachher schicken, habe zu Hause hebräische Tastatur.', '@Beatrix_vStorch @krippmarie CDU soll mit Merkel und SPD weiterhin mit Schulz...!! |LBR| Nur so kann das endgültig beendet werden.....😃😃😃😃', '@SJW_MadBunny @machtjanix23 @Steffmann45 @troll_putin @petpanther0 @mastermikeg @Norbinator2403 @ennof_ @AthinaMala @NancyPeggyMandy @info2099 @lifetrend @ThomasGBauer @SchmiddieMaik @charlie_silve @NoHerrman @willjrosenblatt @feldenfrizz @nasanasal @_macmike @ellibisathide @MD_Franz Das ist ihre Spezialität. Mehr kommt dann aber auch nicht', 'Das Wahlsystem in diesem Schland dient nur einem Zweck, den Bürger zu verarschen, ihn glauben lassen er hätte \"Einfluss\" auf Entscheidungen😜', '@WEBDE_News Was erwartet denn ein zweimaliger Sitzenbleiber, der nicht einmal |LBR| einen Schulabschluss hat, von den deutschen Wählern? Er ist ein |LBR| Blender.', '@Lexie_M_ @MiriamOzen Abnehmen hat sich nicht gelohnt...fett weg Hirn weg...!', '@Libelle2000R Nöööööö, eine Partnerin reicht völlig 😜', '@Beutebadener @bingowist @KotzenderStern Bloß weil du in irgendeiner Partei bist heißt das nicht das du recht hast mein lieber']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "print(random.sample(df[\"tweet\"].to_list(), 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we'd expect, there are Twitter handles to users (`@...`), hashtags (`#...`) and emojis, beside more or less usual punctuation. For a starter, we can perhaps remove the handles (Twitter's usernames are typically not German words) but keep hashtags and emojis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"@handle1 @handle2 some other words or #hashtags @handle3 and finally the end @handle4.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  some other words or #hashtags  and finally the end .\n"
     ]
    }
   ],
   "source": [
    "tmp = re.sub(r\"\\@\\w+\",\"\", string)\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can remove leftover multiple blank spaces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " some other words or #hashtags and finally the end .\n"
     ]
    }
   ],
   "source": [
    "tmp1 = re.sub(r\"\\s+\", \" \", tmp)\n",
    "print(tmp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's a write a simple function to do this cleaning and apply it to the `tweet` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_cleaner(string):\n",
    "    clean_string = re.sub(r\"\\s+\", \" \", re.sub(r\"\\@\\w+\",\"\", string))\n",
    "    return(clean_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: @handle1 @handle2 some other words or #hashtags @handle3 and finally the end @handle4.\n",
      "After:  some other words or #hashtags and finally the end .\n"
     ]
    }
   ],
   "source": [
    "print(\"Before: \" + string)\n",
    "print(\"After: \" + tweet_cleaner(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, \"clean_tweet\"] = df.apply(lambda row : tweet_cleaner(row.tweet), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@corinnamilborn Liebe Corinna, wir würden dich...</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>Liebe Corinna, wir würden dich gerne als Mode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Martin28a Sie haben ja auch Recht. Unser Twee...</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>Sie haben ja auch Recht. Unser Tweet war etwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@ahrens_theo fröhlicher gruß aus der schönsten...</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>fröhlicher gruß aus der schönsten stadt der w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@dushanwegner Amis hätten alles und jeden gewä...</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>Amis hätten alles und jeden gewählt...nur Hil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@spdde kein verläßlicher Verhandlungspartner. ...</td>\n",
       "      <td>OFFENSE</td>\n",
       "      <td>kein verläßlicher Verhandlungspartner. Nachka...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet category  \\\n",
       "0  @corinnamilborn Liebe Corinna, wir würden dich...    OTHER   \n",
       "1  @Martin28a Sie haben ja auch Recht. Unser Twee...    OTHER   \n",
       "2  @ahrens_theo fröhlicher gruß aus der schönsten...    OTHER   \n",
       "3  @dushanwegner Amis hätten alles und jeden gewä...    OTHER   \n",
       "4  @spdde kein verläßlicher Verhandlungspartner. ...  OFFENSE   \n",
       "\n",
       "                                         clean_tweet  \n",
       "0   Liebe Corinna, wir würden dich gerne als Mode...  \n",
       "1   Sie haben ja auch Recht. Unser Tweet war etwa...  \n",
       "2   fröhlicher gruß aus der schönsten stadt der w...  \n",
       "3   Amis hätten alles und jeden gewählt...nur Hil...  \n",
       "4   kein verläßlicher Verhandlungspartner. Nachka...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline models\n",
    "\n",
    "Let's start quick and easy: let's see how Logistic Regression behave with `tf-idf` features, using `sklearn`'s pipelines.\n",
    "\n",
    "First, we split the `df` into training and testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.clean_tweet # features are the cleaned tweets\n",
    "y = df.category # labels are the categories\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42) # split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define a pipeline with vectorizer, tf-idf encoder and logistic regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = Pipeline([('vect', CountVectorizer()), # transform text into matrix of token counts\n",
    "                   ('tfidf', TfidfTransformer()), # from token counts to normalized tf-idf\n",
    "                   ('clf', LogisticRegression(class_weight = \"balanced\")), # logistic regression classifier, class_weight param set to \"cure\" unbalanced labels\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X_train, y_train) # training\n",
    "y_pred = logreg.predict(X_test) # predict labels of test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quickly explore model's performance with the help of `sklearn`'s built-in metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     OFFENSE       0.56      0.64      0.59       497\n",
      "       OTHER       0.81      0.75      0.78      1006\n",
      "\n",
      "    accuracy                           0.71      1503\n",
      "   macro avg       0.68      0.69      0.69      1503\n",
      "weighted avg       0.72      0.71      0.72      1503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with word-level n-gram `tf-idf`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = Pipeline([('vect', CountVectorizer(analyzer = \"word\", token_pattern = r\"\\w{1,}\", ngram_range = (2,3))), # ngrams counts\n",
    "                   ('tfidf', TfidfTransformer()), # normalized tf-idf\n",
    "                   ('clf', LogisticRegression(class_weight = \"balanced\")), # logistic regression\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X_train, y_train) # training\n",
    "y_pred = logreg.predict(X_test) # predict labels of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     OFFENSE       0.56      0.36      0.44       497\n",
      "       OTHER       0.73      0.86      0.79      1006\n",
      "\n",
      "    accuracy                           0.69      1503\n",
      "   macro avg       0.64      0.61      0.61      1503\n",
      "weighted avg       0.67      0.69      0.67      1503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with n-gram character-level `tf-idf`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = Pipeline([('vect', CountVectorizer(analyzer = \"char\", token_pattern = r\"\\w{1,}\", ngram_range = (2,4))), # char-level ngrams counts\n",
    "                   ('tfidf', TfidfTransformer()), # normalized tf-idf\n",
    "                   ('clf', LogisticRegression(class_weight = \"balanced\")), # logistic regression\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X_train, y_train) # training\n",
    "y_pred = logreg.predict(X_test) # predict labels of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     OFFENSE       0.62      0.70      0.66       497\n",
      "       OTHER       0.84      0.78      0.81      1006\n",
      "\n",
      "    accuracy                           0.76      1503\n",
      "   macro avg       0.73      0.74      0.73      1503\n",
      "weighted avg       0.77      0.76      0.76      1503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: the best result was obtained with character-level n-grams and logistic regression. Can we improve on that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcl = Pipeline([('vect', CountVectorizer()), # transform text into matrix of token counts\n",
    "                   ('tfidf', TfidfTransformer()), # from token counts to normalized tf-idf\n",
    "                   ('clf', SVC(class_weight = \"balanced\")), # support vector classifier, default params\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcl.fit(X_train, y_train) # training\n",
    "y_pred = svcl.predict(X_test) # predict labels of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     OFFENSE       0.64      0.53      0.58       497\n",
      "       OTHER       0.78      0.85      0.82      1006\n",
      "\n",
      "    accuracy                           0.75      1503\n",
      "   macro avg       0.71      0.69      0.70      1503\n",
      "weighted avg       0.74      0.75      0.74      1503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already not too far from best LogReg above. How about n-gram features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcl = Pipeline([('vect', CountVectorizer(analyzer = \"word\", token_pattern = r\"\\w{1,}\", ngram_range = (2,3))), # word-level n-grams\n",
    "                   ('tfidf', TfidfTransformer()), # from n-gram counts to normalized tf-idf\n",
    "                   ('clf', SVC(class_weight = \"balanced\")), # support vector classifier\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcl.fit(X_train, y_train) # training\n",
    "y_pred = svcl.predict(X_test) # predict labels of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     OFFENSE       0.73      0.09      0.15       497\n",
      "       OTHER       0.69      0.98      0.81      1006\n",
      "\n",
      "    accuracy                           0.69      1503\n",
      "   macro avg       0.71      0.54      0.48      1503\n",
      "weighted avg       0.70      0.69      0.59      1503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very poor recall of `OFFENSE`: puzzling. How about character-level n-grams?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcl = Pipeline([('vect', CountVectorizer(analyzer = \"char\", token_pattern = r\"\\w{1,}\", ngram_range = (2,4))), # word-level n-grams\n",
    "                   ('tfidf', TfidfTransformer()), # from n-gram counts to normalized tf-idf\n",
    "                   ('clf', SVC(class_weight = \"balanced\")), # support vector classifier\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcl.fit(X_train, y_train) # training\n",
    "y_pred = svcl.predict(X_test) # predict labels of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     OFFENSE       0.71      0.62      0.66       497\n",
      "       OTHER       0.82      0.87      0.85      1006\n",
      "\n",
      "    accuracy                           0.79      1503\n",
      "   macro avg       0.76      0.75      0.75      1503\n",
      "weighted avg       0.78      0.79      0.79      1503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the best so far. We can take it as our new baseline, and try to improve from here, e.g. tuning the parameters of `SVC`.\n",
    "\n",
    "To do so, we try with `sklearn`'s `GridSearchCV`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same pipeline as before\n",
    "svcl = Pipeline([('vect', CountVectorizer(analyzer = \"char\", token_pattern = r\"\\w{1,}\", ngram_range = (2,4))), # word-level n-grams\n",
    "                   ('tfidf', TfidfTransformer()), # from n-gram counts to normalized tf-idf\n",
    "                   ('clf', SVC(class_weight = \"balanced\")), # support vector classifier\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # to define intervals of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid of parameter values\n",
    "param_grid = {\"clf__C\" : np.linspace(0.1, 1, num = 10), # regularization\n",
    "              \"clf__gamma\" : np.linspace(0.1, 1, num = 10) # kernel coefficient\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(svcl, param_grid, verbose = 10, n_jobs=-1) # n_job=-1 in order to use all available processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 14.3min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed: 16.7min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed: 18.6min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed: 21.6min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 24.2min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed: 27.1min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 30.1min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed: 34.2min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed: 37.7min\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed: 41.3min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 44.6min\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed: 49.5min\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed: 53.6min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed: 57.6min\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed: 61.3min\n",
      "[Parallel(n_jobs=-1)]: Done 413 tasks      | elapsed: 66.1min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 70.6min\n",
      "[Parallel(n_jobs=-1)]: Done 473 tasks      | elapsed: 75.5min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed: 79.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        CountVectorizer(analyzer='char',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(2, 4),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=None,\n",
       "                                                        token_pattern='\\...\n",
       "                                            degree=3, gamma=1, kernel='rbf',\n",
       "                                            max_iter=-1, probability=False,\n",
       "                                            random_state=None, shrinking=True,\n",
       "                                            tol=0.001, verbose=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'clf__C': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       "                         'clf__gamma': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=10)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(X_train, y_train) # this will take a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.758):\n",
      "{'clf__C': 1.0, 'clf__gamma': 0.7000000000000001}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`C=1` is the default value; not sure about `gamma`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcl = Pipeline([('vect', CountVectorizer(analyzer = \"char\", token_pattern = r\"\\w{1,}\", ngram_range = (2,4))), # word-level n-grams\n",
    "                   ('tfidf', TfidfTransformer()), # from n-gram counts to normalized tf-idf\n",
    "                   ('clf', SVC(C = 1, gamma = 0.7, class_weight = \"balanced\")), # support vector classifier\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcl.fit(X_train, y_train) # training\n",
    "y_pred = svcl.predict(X_test) # predict labels of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     OFFENSE       0.65      0.67      0.66       497\n",
      "       OTHER       0.84      0.82      0.83      1006\n",
      "\n",
      "    accuracy                           0.77      1503\n",
      "   macro avg       0.74      0.75      0.75      1503\n",
      "weighted avg       0.78      0.77      0.77      1503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worse results compared to model with default parameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': venv)",
   "language": "python",
   "name": "python37664bitbasevenv23cd022687ab470688da671eade16340"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
