{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitbasevenvb8febc2764254ae2abe0685f99c2de92",
   "display_name": "Python 3.7.6 64-bit ('base': venv)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 7\n",
    "## GermEval 2018 shared task: identification of offensive language\n",
    "\n",
    "GermEval task: https://projects.fzai.h-da.de/iggsa/germeval-2018/\n",
    "\n",
    "Assignment: https://snlp2018.github.io/assignments.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "The goal of Task 1 is to detect offensive language in social media posts in German: tweets have to be classified as either `OFFENSE` or `OTHER`.\n",
    "\n",
    "Data: https://github.com/uds-lsv/GermEval-2018-Data\n",
    "\n",
    "The file `germeval2018.training.txt` is a tab-separated list of labelled tweets; this is the development set to be used in training and tuning of model(s). The file `germeval2018.test.txt` contains the \"gold-standard\" data against which the final model should be (and has been, in the actual shared task) evaluated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The data\n",
    "First of all, let's read and take a quick look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/germeval2018.training.txt\", sep = \"\\t\", encoding = \"utf-8\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                   0        1       2\n0  @corinnamilborn Liebe Corinna, wir w√ºrden dich...    OTHER   OTHER\n1  @Martin28a Sie haben ja auch Recht. Unser Twee...    OTHER   OTHER\n2  @ahrens_theo fr√∂hlicher gru√ü aus der sch√∂nsten...    OTHER   OTHER\n3  @dushanwegner Amis h√§tten alles und jeden gew√§...    OTHER   OTHER\n4  @spdde kein verl√§√ülicher Verhandlungspartner. ...  OFFENSE  INSULT",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@corinnamilborn Liebe Corinna, wir w√ºrden dich...</td>\n      <td>OTHER</td>\n      <td>OTHER</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@Martin28a Sie haben ja auch Recht. Unser Twee...</td>\n      <td>OTHER</td>\n      <td>OTHER</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@ahrens_theo fr√∂hlicher gru√ü aus der sch√∂nsten...</td>\n      <td>OTHER</td>\n      <td>OTHER</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@dushanwegner Amis h√§tten alles und jeden gew√§...</td>\n      <td>OTHER</td>\n      <td>OTHER</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@spdde kein verl√§√ülicher Verhandlungspartner. ...</td>\n      <td>OFFENSE</td>\n      <td>INSULT</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe: first column contains tweet and second column the labels `OFFENSE` or `OTHER`; third column contains finer-grained labeling which we are not interesed in at the moment. Let's drop the latter and give the other two columns user-friendly names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.columns[2], axis = 1, inplace = True)\n",
    "df.columns = [\"tweet\", \"category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                               tweet category\n0  @corinnamilborn Liebe Corinna, wir w√ºrden dich...    OTHER\n1  @Martin28a Sie haben ja auch Recht. Unser Twee...    OTHER\n2  @ahrens_theo fr√∂hlicher gru√ü aus der sch√∂nsten...    OTHER\n3  @dushanwegner Amis h√§tten alles und jeden gew√§...    OTHER\n4  @spdde kein verl√§√ülicher Verhandlungspartner. ...  OFFENSE",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@corinnamilborn Liebe Corinna, wir w√ºrden dich...</td>\n      <td>OTHER</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@Martin28a Sie haben ja auch Recht. Unser Twee...</td>\n      <td>OTHER</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@ahrens_theo fr√∂hlicher gru√ü aus der sch√∂nsten...</td>\n      <td>OTHER</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@dushanwegner Amis h√§tten alles und jeden gew√§...</td>\n      <td>OTHER</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@spdde kein verl√§√ülicher Verhandlungspartner. ...</td>\n      <td>OFFENSE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the data balanced? Let's find out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "          tweet\ncategory       \nOFFENSE    1688\nOTHER      3321",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n    </tr>\n    <tr>\n      <th>category</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>OFFENSE</th>\n      <td>1688</td>\n    </tr>\n    <tr>\n      <th>OTHER</th>\n      <td>3321</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df.groupby(\"category\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not quite, there are twice as many tweets labelled as `OTHER` than tweets labelled as `OFFENSE`. Is this a problem? It can be; so: 1) we won't use accuracy but precision and recall metrics and 2) we might need to weight the loss function(s) of our model(s). We'll come back to this later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing\n",
    "\n",
    "What do the tweets look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['@HStiebert @eroloenal @welt T√ºrken sollten besser den Ball flach halten. Ich hab die Fahnen gesehen.', '@Beatrix_vStorch Es stimmt....H√∂cke k√∂nnte zum Problem werden....Politik ist auch Diplomatie, die muss gewahrt werden!', 'Wenn Merkel u. ihre Speichellecker √ºber Demokratie sprechen ist es in etwa so, als wenn der \"1000-J√§hrige\" √ºber Frieden sprach &gt; HINTERLISTüòú', '@Ralf_Stegner Ralle du alter M√ºlleimer lebst ja immer noch...dachte das zeitliche hat dich gesegnet... |LBR| Bist halt eine z√§he Unkrautwurzel', 'Warum hat wohl der Terrorf√ºrst Yassir #Arafat das Wort ¬ª#Pal√§stinenser¬´ f√ºr die #Araber in der #Levante benutzt? Dieses Volk gab es vorher nicht, aber man bediente sich aus dem #Antisemitismus der #R√∂mer, die uns #Juden dem√ºtigten &amp; Eretz #Israel in #Pal√§stina¬´ unbenannten.', '@AfD_Support Wieso ist so ein linker Anarchist noch auf freien Fu√ü.Einsperren und verschimmeln lassen', 'Wie kommt es eigentlich, dass alle den M√∂lzer einladen, aber so wenig √ºber die vom Staat verfolgten Refugees berichtet wird...', '@krippmarie Obwohl sie zurecht als verlieren gelten d√ºrfen sie dennoch weiter regieren....', 'Gauland hat recht !! Was hat eine aus der Ziegenrasse in Deutschland,im Besonderen in üá©üá™er Politik zu suchen? Nichts ! Fakt !', 'Grenzkontrollen bis der Schutz der EU-Au√üengrenzen funktioniert! #TVDuell']\n"
    }
   ],
   "source": [
    "import random\n",
    "print(random.sample(df[\"tweet\"].to_list(), 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we'd expect, there are Twitter handles to users (`@...`), hashtags (`#...`) and emojis, beside more or less usual punctuation. For a starter, we can perhaps remove the handles (Twitter's usernames are typically not German words) but keep hashtags and emojis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"@handle1 @handle2 some other words or #hashtags @handle3 and finally the end @handle4.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "some other words or #hashtags  and finally the end .\n"
    }
   ],
   "source": [
    "tmp = re.sub(r\"\\@\\w+\",\"\", string)\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can remove leftover multiple blank spaces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "some other words or #hashtags and finally the end .\n"
    }
   ],
   "source": [
    "tmp1 = re.sub(r\"\\s+\", \" \", tmp)\n",
    "print(tmp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's a write a simple function to do this cleaning and apply it to the `tweet` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_cleaner(string):\n",
    "    clean_string = re.sub(r\"\\s+\", \" \", re.sub(r\"\\@\\w+\",\"\", string))\n",
    "    return(clean_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Before: @handle1 @handle2 some other words or #hashtags @handle3 and finally the end @handle4.\nAfter:  some other words or #hashtags and finally the end .\n"
    }
   ],
   "source": [
    "print(\"Before: \" + string)\n",
    "print(\"After: \" + tweet_cleaner(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, \"clean_tweet\"] = df.apply(lambda row : tweet_cleaner(row.tweet), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                               tweet category  \\\n0  @corinnamilborn Liebe Corinna, wir w√ºrden dich...    OTHER   \n1  @Martin28a Sie haben ja auch Recht. Unser Twee...    OTHER   \n2  @ahrens_theo fr√∂hlicher gru√ü aus der sch√∂nsten...    OTHER   \n3  @dushanwegner Amis h√§tten alles und jeden gew√§...    OTHER   \n4  @spdde kein verl√§√ülicher Verhandlungspartner. ...  OFFENSE   \n\n                                         clean_tweet  \n0   Liebe Corinna, wir w√ºrden dich gerne als Mode...  \n1   Sie haben ja auch Recht. Unser Tweet war etwa...  \n2   fr√∂hlicher gru√ü aus der sch√∂nsten stadt der w...  \n3   Amis h√§tten alles und jeden gew√§hlt...nur Hil...  \n4   kein verl√§√ülicher Verhandlungspartner. Nachka...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n      <th>category</th>\n      <th>clean_tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@corinnamilborn Liebe Corinna, wir w√ºrden dich...</td>\n      <td>OTHER</td>\n      <td>Liebe Corinna, wir w√ºrden dich gerne als Mode...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@Martin28a Sie haben ja auch Recht. Unser Twee...</td>\n      <td>OTHER</td>\n      <td>Sie haben ja auch Recht. Unser Tweet war etwa...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@ahrens_theo fr√∂hlicher gru√ü aus der sch√∂nsten...</td>\n      <td>OTHER</td>\n      <td>fr√∂hlicher gru√ü aus der sch√∂nsten stadt der w...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@dushanwegner Amis h√§tten alles und jeden gew√§...</td>\n      <td>OTHER</td>\n      <td>Amis h√§tten alles und jeden gew√§hlt...nur Hil...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@spdde kein verl√§√ülicher Verhandlungspartner. ...</td>\n      <td>OFFENSE</td>\n      <td>kein verl√§√ülicher Verhandlungspartner. Nachka...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline models\n",
    "\n",
    "Let's start quick and easy: let's see how Logistic Regression behave with `tf-idf` features, using `sklearn`'s pipelines.\n",
    "\n",
    "First, we split the `df` into training and testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.clean_tweet # features are the cleaned tweets\n",
    "y = df.category # labels are the categories\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42) # split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define a pipeline with vectorizer, tf-idf encoder and logistic regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = Pipeline([('vect', CountVectorizer()), # transform text into matrix of token counts\n",
    "                   ('tfidf', TfidfTransformer()), # from token counts to normalized tf-idf\n",
    "                   ('clf', LogisticRegression(class_weight = \"balanced\")), # logistic regression classifier, class_weight param set to \"cure\" unbalanced labels\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X_train, y_train) # training, with weighted samples\n",
    "y_pred = logreg.predict(X_test) # predict labels of test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quickly explore model's performance with the help of `sklearn`'s built-in metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n     OFFENSE       0.56      0.64      0.59       497\n       OTHER       0.81      0.75      0.78      1006\n\n    accuracy                           0.71      1503\n   macro avg       0.68      0.69      0.69      1503\nweighted avg       0.72      0.71      0.72      1503\n\n"
    }
   ],
   "source": [
    "# print report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with word-level n-gram `tf-idf`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = Pipeline([('vect', CountVectorizer(analyzer = \"word\", token_pattern = r\"\\w{1,}\", ngram_range = (2,3))), # ngrams counts\n",
    "                   ('tfidf', TfidfTransformer()), # normalized tf-idf\n",
    "                   ('clf', LogisticRegression(class_weight = \"balanced\")), # logistic regression\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X_train, y_train) # training, with sample weights\n",
    "y_pred = logreg.predict(X_test) # predict labels of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n     OFFENSE       0.56      0.36      0.44       497\n       OTHER       0.73      0.86      0.79      1006\n\n    accuracy                           0.69      1503\n   macro avg       0.64      0.61      0.61      1503\nweighted avg       0.67      0.69      0.67      1503\n\n"
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with n-gram character-level `tf-idf`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = Pipeline([('vect', CountVectorizer(analyzer = \"char\", token_pattern = r\"\\w{1,}\", ngram_range = (2,4))), # char-level ngrams counts\n",
    "                   ('tfidf', TfidfTransformer()), # normalized tf-idf\n",
    "                   ('clf', LogisticRegression(class_weight = \"balanced\")), # logistic regression\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X_train, y_train) # training, with sample weights\n",
    "y_pred = logreg.predict(X_test) # predict labels of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n     OFFENSE       0.62      0.70      0.66       497\n       OTHER       0.84      0.78      0.81      1006\n\n    accuracy                           0.76      1503\n   macro avg       0.73      0.74      0.73      1503\nweighted avg       0.77      0.76      0.76      1503\n\n"
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: the best result was obtained with character-level n-grams and logistic regression. Can we improve on that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcl = Pipeline([('vect', CountVectorizer()), # transform text into matrix of token counts\n",
    "                   ('tfidf', TfidfTransformer()), # from token counts to normalized tf-idf\n",
    "                   ('clf', SVC(class_weight = \"balanced\")), # support vector classifier\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcl.fit(X_train, y_train) # training, with sample weights\n",
    "y_pred = svcl.predict(X_test) # predict labels of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n     OFFENSE       0.64      0.53      0.58       497\n       OTHER       0.78      0.85      0.82      1006\n\n    accuracy                           0.75      1503\n   macro avg       0.71      0.69      0.70      1503\nweighted avg       0.74      0.75      0.74      1503\n\n"
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already not too far from best LogReg above. How about n-gram features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcl = Pipeline([('vect', CountVectorizer(analyzer = \"word\", token_pattern = r\"\\w{1,}\", ngram_range = (2,3))), # word-level n-grams\n",
    "                   ('tfidf', TfidfTransformer()), # from n-gram counts to normalized tf-idf\n",
    "                   ('clf', SVC(class_weight = \"balanced\")), # support vector classifier\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcl.fit(X_train, y_train) # training, with sample weights\n",
    "y_pred = svcl.predict(X_test) # predict labels of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n     OFFENSE       0.73      0.09      0.15       497\n       OTHER       0.69      0.98      0.81      1006\n\n    accuracy                           0.69      1503\n   macro avg       0.71      0.54      0.48      1503\nweighted avg       0.70      0.69      0.59      1503\n\n"
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very poor recall of `OFFENSE`: puzzling. How about character-level n-grams?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcl = Pipeline([('vect', CountVectorizer(analyzer = \"char\", token_pattern = r\"\\w{1,}\", ngram_range = (2,4))), # word-level n-grams\n",
    "                   ('tfidf', TfidfTransformer()), # from n-gram counts to normalized tf-idf\n",
    "                   ('clf', SVC(class_weight = \"balanced\")), # support vector classifier\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcl.fit(X_train, y_train) # training, with sample weights\n",
    "y_pred = svcl.predict(X_test) # predict labels of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n     OFFENSE       0.71      0.62      0.66       497\n       OTHER       0.82      0.87      0.85      1006\n\n    accuracy                           0.79      1503\n   macro avg       0.76      0.75      0.75      1503\nweighted avg       0.78      0.79      0.79      1503\n\n"
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the best so far. We can take it as our new baseline, and try to improve from here, e.g. tuning the parameters of `SVC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}