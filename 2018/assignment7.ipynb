{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 7\n",
    "## GermEval 2018 shared task: identification of offensive language\n",
    "\n",
    "GermEval task: https://projects.fzai.h-da.de/iggsa/germeval-2018/\n",
    "\n",
    "Assignment: https://snlp2018.github.io/assignments.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "The goal of Task 1 is to detect offensive language in social media posts in German: tweets have to be classified as either `OFFENSE` or `OTHER`.\n",
    "\n",
    "Data: https://github.com/uds-lsv/GermEval-2018-Data\n",
    "\n",
    "The file `germeval2018.training.txt` is a tab-separated list of labelled tweets; this is the development set to be used in training and tuning of model(s). The file `germeval2018.test.txt` contains the \"gold-standard\" data against which the final model should be (and has been, in the actual shared task) evaluated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The data\n",
    "First of all, let's read and take a quick look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/germeval2018.training.txt\", sep = \"\\t\", encoding = \"utf-8\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@corinnamilborn Liebe Corinna, wir w√ºrden dich...</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Martin28a Sie haben ja auch Recht. Unser Twee...</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@ahrens_theo fr√∂hlicher gru√ü aus der sch√∂nsten...</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@dushanwegner Amis h√§tten alles und jeden gew√§...</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@spdde kein verl√§√ülicher Verhandlungspartner. ...</td>\n",
       "      <td>OFFENSE</td>\n",
       "      <td>INSULT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0        1       2\n",
       "0  @corinnamilborn Liebe Corinna, wir w√ºrden dich...    OTHER   OTHER\n",
       "1  @Martin28a Sie haben ja auch Recht. Unser Twee...    OTHER   OTHER\n",
       "2  @ahrens_theo fr√∂hlicher gru√ü aus der sch√∂nsten...    OTHER   OTHER\n",
       "3  @dushanwegner Amis h√§tten alles und jeden gew√§...    OTHER   OTHER\n",
       "4  @spdde kein verl√§√ülicher Verhandlungspartner. ...  OFFENSE  INSULT"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe: first column contains tweet and second column the labels `OFFENSE` or `OTHER`; third column contains finer-grained labeling which we are not interesed in at the moment. Let's drop the latter and give the other two columns user-friendly names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.columns[2], axis = 1, inplace = True)\n",
    "df.columns = [\"tweet\", \"category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@corinnamilborn Liebe Corinna, wir w√ºrden dich...</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Martin28a Sie haben ja auch Recht. Unser Twee...</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@ahrens_theo fr√∂hlicher gru√ü aus der sch√∂nsten...</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@dushanwegner Amis h√§tten alles und jeden gew√§...</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@spdde kein verl√§√ülicher Verhandlungspartner. ...</td>\n",
       "      <td>OFFENSE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet category\n",
       "0  @corinnamilborn Liebe Corinna, wir w√ºrden dich...    OTHER\n",
       "1  @Martin28a Sie haben ja auch Recht. Unser Twee...    OTHER\n",
       "2  @ahrens_theo fr√∂hlicher gru√ü aus der sch√∂nsten...    OTHER\n",
       "3  @dushanwegner Amis h√§tten alles und jeden gew√§...    OTHER\n",
       "4  @spdde kein verl√§√ülicher Verhandlungspartner. ...  OFFENSE"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the data balanced? Let's find out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OFFENSE</th>\n",
       "      <td>1688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OTHER</th>\n",
       "      <td>3321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tweet\n",
       "category       \n",
       "OFFENSE    1688\n",
       "OTHER      3321"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"category\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not quite, there are twice as many tweets labelled as `OTHER` than tweets labelled as `OFFENSE`. Is this a problem? It can be; so: 1) we won't use accuracy but precision and recall metrics and 2) we might need to weight the loss function(s) of our model(s). We'll come back to this later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing\n",
    "\n",
    "What do the tweets look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Steuermehreinnahmen. Wof√ºr? Bl√∂de Frage. Es gibt so viele L√∂cher, |LBR| die gestopft werden m√ºssen. H√∂rt auf mit Steuergeschenken.', '@bettisweb @dannytastisch Hi, Marktplatz 40213 D√ºsseldorf um 14 Uhr.', '@X9donernesto @petpanther0 @machtjanix23 @NoHerrman @teite99 @info2099 @lifetrend @ThomasGBauer @SchmiddieMaik @AthinaMala @charlie_silve @willjrosenblatt @feldenfrizz @nasanasal @_macmike @ellibisathide @MD_Franz Kann ich Dir nachher schicken, habe zu Hause hebr√§ische Tastatur.', '@Beatrix_vStorch @krippmarie CDU soll mit Merkel und SPD weiterhin mit Schulz...!! |LBR| Nur so kann das endg√ºltig beendet werden.....üòÉüòÉüòÉüòÉ', '@SJW_MadBunny @machtjanix23 @Steffmann45 @troll_putin @petpanther0 @mastermikeg @Norbinator2403 @ennof_ @AthinaMala @NancyPeggyMandy @info2099 @lifetrend @ThomasGBauer @SchmiddieMaik @charlie_silve @NoHerrman @willjrosenblatt @feldenfrizz @nasanasal @_macmike @ellibisathide @MD_Franz Das ist ihre Spezialit√§t. Mehr kommt dann aber auch nicht', 'Das Wahlsystem in diesem Schland dient nur einem Zweck, den B√ºrger zu verarschen, ihn glauben lassen er h√§tte \"Einfluss\" auf Entscheidungenüòú', '@WEBDE_News Was erwartet denn ein zweimaliger Sitzenbleiber, der nicht einmal |LBR| einen Schulabschluss hat, von den deutschen W√§hlern? Er ist ein |LBR| Blender.', '@Lexie_M_ @MiriamOzen Abnehmen hat sich nicht gelohnt...fett weg Hirn weg...!', '@Libelle2000R N√∂√∂√∂√∂√∂√∂, eine Partnerin reicht v√∂llig üòú', '@Beutebadener @bingowist @KotzenderStern Blo√ü weil du in irgendeiner Partei bist hei√üt das nicht das du recht hast mein lieber']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "print(random.sample(df[\"tweet\"].to_list(), 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we'd expect, there are Twitter handles to users (`@...`), hashtags (`#...`) and emojis, beside more or less usual punctuation. For a starter, we can perhaps remove the handles (Twitter's usernames are typically not German words) but keep hashtags and emojis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"@handle1 @handle2 some other words or #hashtags @handle3 and finally the end @handle4.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  some other words or #hashtags  and finally the end .\n"
     ]
    }
   ],
   "source": [
    "tmp = re.sub(r\"\\@\\w+\",\"\", string)\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can remove leftover multiple blank spaces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " some other words or #hashtags and finally the end .\n"
     ]
    }
   ],
   "source": [
    "tmp1 = re.sub(r\"\\s+\", \" \", tmp)\n",
    "print(tmp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's a write a simple function to do this cleaning and apply it to the `tweet` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_cleaner(string):\n",
    "    clean_string = re.sub(r\"\\s+\", \" \", re.sub(r\"\\@\\w+\",\"\", string))\n",
    "    return(clean_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: @handle1 @handle2 some other words or #hashtags @handle3 and finally the end @handle4.\n",
      "After:  some other words or #hashtags and finally the end .\n"
     ]
    }
   ],
   "source": [
    "print(\"Before: \" + string)\n",
    "print(\"After: \" + tweet_cleaner(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, \"clean_tweet\"] = df.apply(lambda row : tweet_cleaner(row.tweet), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@corinnamilborn Liebe Corinna, wir w√ºrden dich...</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>Liebe Corinna, wir w√ºrden dich gerne als Mode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Martin28a Sie haben ja auch Recht. Unser Twee...</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>Sie haben ja auch Recht. Unser Tweet war etwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@ahrens_theo fr√∂hlicher gru√ü aus der sch√∂nsten...</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>fr√∂hlicher gru√ü aus der sch√∂nsten stadt der w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@dushanwegner Amis h√§tten alles und jeden gew√§...</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>Amis h√§tten alles und jeden gew√§hlt...nur Hil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@spdde kein verl√§√ülicher Verhandlungspartner. ...</td>\n",
       "      <td>OFFENSE</td>\n",
       "      <td>kein verl√§√ülicher Verhandlungspartner. Nachka...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet category  \\\n",
       "0  @corinnamilborn Liebe Corinna, wir w√ºrden dich...    OTHER   \n",
       "1  @Martin28a Sie haben ja auch Recht. Unser Twee...    OTHER   \n",
       "2  @ahrens_theo fr√∂hlicher gru√ü aus der sch√∂nsten...    OTHER   \n",
       "3  @dushanwegner Amis h√§tten alles und jeden gew√§...    OTHER   \n",
       "4  @spdde kein verl√§√ülicher Verhandlungspartner. ...  OFFENSE   \n",
       "\n",
       "                                         clean_tweet  \n",
       "0   Liebe Corinna, wir w√ºrden dich gerne als Mode...  \n",
       "1   Sie haben ja auch Recht. Unser Tweet war etwa...  \n",
       "2   fr√∂hlicher gru√ü aus der sch√∂nsten stadt der w...  \n",
       "3   Amis h√§tten alles und jeden gew√§hlt...nur Hil...  \n",
       "4   kein verl√§√ülicher Verhandlungspartner. Nachka...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline models\n",
    "\n",
    "Let's start quick and easy: let's see how Logistic Regression behave with `tf-idf` features, using `sklearn`'s pipelines.\n",
    "\n",
    "First, we split the `df` into training and testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.clean_tweet # features are the cleaned tweets\n",
    "y = df.category # labels are the categories\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42) # split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define a pipeline with vectorizer, tf-idf encoder and logistic regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = Pipeline([('vect', CountVectorizer()), # transform text into matrix of token counts\n",
    "                   ('tfidf', TfidfTransformer()), # from token counts to normalized tf-idf\n",
    "                   ('clf', LogisticRegression(class_weight = \"balanced\")), # logistic regression classifier, class_weight param set to \"cure\" unbalanced labels\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X_train, y_train) # training\n",
    "y_pred = logreg.predict(X_test) # predict labels of test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quickly explore model's performance with the help of `sklearn`'s built-in metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     OFFENSE       0.56      0.64      0.59       497\n",
      "       OTHER       0.81      0.75      0.78      1006\n",
      "\n",
      "    accuracy                           0.71      1503\n",
      "   macro avg       0.68      0.69      0.69      1503\n",
      "weighted avg       0.72      0.71      0.72      1503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with word-level n-gram `tf-idf`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = Pipeline([('vect', CountVectorizer(analyzer = \"word\", token_pattern = r\"\\w{1,}\", ngram_range = (2,3))), # ngrams counts\n",
    "                   ('tfidf', TfidfTransformer()), # normalized tf-idf\n",
    "                   ('clf', LogisticRegression(class_weight = \"balanced\")), # logistic regression\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X_train, y_train) # training\n",
    "y_pred = logreg.predict(X_test) # predict labels of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     OFFENSE       0.56      0.36      0.44       497\n",
      "       OTHER       0.73      0.86      0.79      1006\n",
      "\n",
      "    accuracy                           0.69      1503\n",
      "   macro avg       0.64      0.61      0.61      1503\n",
      "weighted avg       0.67      0.69      0.67      1503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with n-gram character-level `tf-idf`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = Pipeline([('vect', CountVectorizer(analyzer = \"char\", token_pattern = r\"\\w{1,}\", ngram_range = (2,4))), # char-level ngrams counts\n",
    "                   ('tfidf', TfidfTransformer()), # normalized tf-idf\n",
    "                   ('clf', LogisticRegression(class_weight = \"balanced\")), # logistic regression\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X_train, y_train) # training\n",
    "y_pred = logreg.predict(X_test) # predict labels of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     OFFENSE       0.62      0.70      0.66       497\n",
      "       OTHER       0.84      0.78      0.81      1006\n",
      "\n",
      "    accuracy                           0.76      1503\n",
      "   macro avg       0.73      0.74      0.73      1503\n",
      "weighted avg       0.77      0.76      0.76      1503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: the best result was obtained with character-level n-grams and logistic regression. Can we improve on that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcl = Pipeline([('vect', CountVectorizer()), # transform text into matrix of token counts\n",
    "                   ('tfidf', TfidfTransformer()), # from token counts to normalized tf-idf\n",
    "                   ('clf', SVC(class_weight = \"balanced\")), # support vector classifier, default params\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcl.fit(X_train, y_train) # training\n",
    "y_pred = svcl.predict(X_test) # predict labels of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     OFFENSE       0.64      0.53      0.58       497\n",
      "       OTHER       0.78      0.85      0.82      1006\n",
      "\n",
      "    accuracy                           0.75      1503\n",
      "   macro avg       0.71      0.69      0.70      1503\n",
      "weighted avg       0.74      0.75      0.74      1503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already not too far from best LogReg above. How about n-gram features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcl = Pipeline([('vect', CountVectorizer(analyzer = \"word\", token_pattern = r\"\\w{1,}\", ngram_range = (2,3))), # word-level n-grams\n",
    "                   ('tfidf', TfidfTransformer()), # from n-gram counts to normalized tf-idf\n",
    "                   ('clf', SVC(class_weight = \"balanced\")), # support vector classifier\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcl.fit(X_train, y_train) # training\n",
    "y_pred = svcl.predict(X_test) # predict labels of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     OFFENSE       0.73      0.09      0.15       497\n",
      "       OTHER       0.69      0.98      0.81      1006\n",
      "\n",
      "    accuracy                           0.69      1503\n",
      "   macro avg       0.71      0.54      0.48      1503\n",
      "weighted avg       0.70      0.69      0.59      1503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very poor recall of `OFFENSE`: puzzling. How about character-level n-grams?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcl = Pipeline([('vect', CountVectorizer(analyzer = \"char\", token_pattern = r\"\\w{1,}\", ngram_range = (2,4))), # word-level n-grams\n",
    "                   ('tfidf', TfidfTransformer()), # from n-gram counts to normalized tf-idf\n",
    "                   ('clf', SVC(class_weight = \"balanced\")), # support vector classifier\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcl.fit(X_train, y_train) # training\n",
    "y_pred = svcl.predict(X_test) # predict labels of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     OFFENSE       0.71      0.62      0.66       497\n",
      "       OTHER       0.82      0.87      0.85      1006\n",
      "\n",
      "    accuracy                           0.79      1503\n",
      "   macro avg       0.76      0.75      0.75      1503\n",
      "weighted avg       0.78      0.79      0.79      1503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the best so far. We can take it as our new baseline, and try to improve from here, e.g. tuning the parameters of `SVC`.\n",
    "\n",
    "To do so, we try with `sklearn`'s `GridSearchCV`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same pipeline as before\n",
    "svcl = Pipeline([('vect', CountVectorizer(analyzer = \"char\", token_pattern = r\"\\w{1,}\", ngram_range = (2,4))), # word-level n-grams\n",
    "                   ('tfidf', TfidfTransformer()), # from n-gram counts to normalized tf-idf\n",
    "                   ('clf', SVC(class_weight = \"balanced\")), # support vector classifier\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # to define intervals of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid of parameter values\n",
    "param_grid = {\"clf__C\" : np.linspace(0.1, 1, num = 10), # regularization\n",
    "              \"clf__gamma\" : np.linspace(0.1, 1, num = 10) # kernel coefficient\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(svcl, param_grid, verbose = 10, n_jobs=-1) # n_job=-1 in order to use all available processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 14.3min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed: 16.7min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed: 18.6min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed: 21.6min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 24.2min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed: 27.1min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 30.1min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed: 34.2min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed: 37.7min\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed: 41.3min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 44.6min\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed: 49.5min\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed: 53.6min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed: 57.6min\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed: 61.3min\n",
      "[Parallel(n_jobs=-1)]: Done 413 tasks      | elapsed: 66.1min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 70.6min\n",
      "[Parallel(n_jobs=-1)]: Done 473 tasks      | elapsed: 75.5min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed: 79.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        CountVectorizer(analyzer='char',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(2, 4),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=None,\n",
       "                                                        token_pattern='\\...\n",
       "                                            degree=3, gamma=1, kernel='rbf',\n",
       "                                            max_iter=-1, probability=False,\n",
       "                                            random_state=None, shrinking=True,\n",
       "                                            tol=0.001, verbose=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'clf__C': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       "                         'clf__gamma': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=10)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(X_train, y_train) # this will take a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.758):\n",
      "{'clf__C': 1.0, 'clf__gamma': 0.7000000000000001}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`C=1` is the default value; not sure about `gamma`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcl = Pipeline([('vect', CountVectorizer(analyzer = \"char\", token_pattern = r\"\\w{1,}\", ngram_range = (2,4))), # word-level n-grams\n",
    "                   ('tfidf', TfidfTransformer()), # from n-gram counts to normalized tf-idf\n",
    "                   ('clf', SVC(C = 1, gamma = 0.7, class_weight = \"balanced\")), # support vector classifier\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcl.fit(X_train, y_train) # training\n",
    "y_pred = svcl.predict(X_test) # predict labels of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     OFFENSE       0.65      0.67      0.66       497\n",
      "       OTHER       0.84      0.82      0.83      1006\n",
      "\n",
      "    accuracy                           0.77      1503\n",
      "   macro avg       0.74      0.75      0.75      1503\n",
      "weighted avg       0.78      0.77      0.77      1503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worse results compared to model with default parameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': venv)",
   "language": "python",
   "name": "python37664bitbasevenv23cd022687ab470688da671eade16340"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
