{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TueSNLP 2019 - Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying languages\n",
    "\n",
    "The assignment and data are available at https://snlp2019.github.io/a2/\n",
    "\n",
    "The data is a subset of WALS (https://wals.info/) and it consists of a tab-separated file with a `family` column containing the family of a language and other columns containing features for the language (notice: one language per row, first row is header and first two columns not essential)\n",
    "\n",
    "The goal of the assignment is to learn language classification based on typological features.\n",
    "\n",
    "(as per assignment instructions, our code roughly follows the template(s) provided)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1. Encoding the data\n",
    "\n",
    "We write a function `encode()` which reads the data file and returns two numpy arrays, `labels` and `feature`; the former is the list of language families, the latter is a 2d array with as many rows as there are labels, where each row is the concatenation of the one-hot encodings of the features corresponding to the label. `NA`s and unknown values will be mapped to vectors of `0`s.\n",
    "\n",
    "We do this step-by-step, then we put everything together in a function definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data and take a look\n",
    "df = pd.read_csv(\"data/wals-train.tsv\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  lcode              lname        family  \\\n0   amh            Amharic  Afro-Asiatic   \n1   arz  Arabic (Egyptian)  Afro-Asiatic   \n2   bej               Beja  Afro-Asiatic   \n3   heb    Hebrew (Modern)  Afro-Asiatic   \n4   irk              Iraqw  Afro-Asiatic   \n\n  143A Order of Negative Morpheme and Verb 143F Postverbal Negative Morphemes  \\\n0                        14 ObligDoubleNeg                          2 [V-Neg]   \n1                          15 OptDoubleNeg                          2 [V-Neg]   \n2                                3 [Neg-V]                             4 None   \n3                                   1 NegV                             4 None   \n4                                4 [V-Neg]                          2 [V-Neg]   \n\n  143G Minor morphological means of signaling negation  \\\n0                                             4 None     \n1                                             4 None     \n2                                             4 None     \n3                                             4 None     \n4                                             4 None     \n\n  82A Order of Subject and Verb 143E Preverbal Negative Morphemes  \\\n0                          1 SV                         2 [Neg-V]   \n1                          1 SV                    3 NegV&[Neg-V]   \n2                          1 SV                         2 [Neg-V]   \n3                          1 SV                            1 NegV   \n4                          1 SV                            4 None   \n\n  83A Order of Object and Verb 85A Order of Adposition and Noun Phrase  ...  \\\n0                         1 OV                     4 No dominant order  ...   \n1                         2 VO                          2 Prepositions  ...   \n2                         1 OV                         1 Postpositions  ...   \n3                         2 VO                          2 Prepositions  ...   \n4                         1 OV                          2 Prepositions  ...   \n\n  19A Presence of Uncommon Consonants 3A Consonant-Vowel Ratio  \\\n0                              1 None        4 Moderately high   \n1                       4 Pharyngeals        4 Moderately high   \n2                              1 None                3 Average   \n3                                 NaN                      NaN   \n4                       4 Pharyngeals                   5 High   \n\n          8A Lateral Consonants            6A Uvular Consonants  \\\n0  2 /l/, no obstruent laterals                          1 None   \n1  2 /l/, no obstruent laterals  4 Uvular stops and continuants   \n2  2 /l/, no obstruent laterals                          1 None   \n3                           NaN                             NaN   \n4   4 /l/ and lateral obstruent             2 Uvular stops only   \n\n  18A Absence of Common Consonants 69A Position of Tense-Aspect Affixes  \\\n0                    1 All present                         4 Mixed type   \n1                    1 All present                         4 Mixed type   \n2                    1 All present              2 Tense-aspect suffixes   \n3                              NaN                         4 Mixed type   \n4                    1 All present         5 No tense-aspect inflection   \n\n  112A Negative Morphemes 107A Passive Constructions  \\\n0       6 Double negation                  1 Present   \n1     2 Negative particle                  1 Present   \n2        1 Negative affix                  1 Present   \n3     2 Negative particle                  1 Present   \n4        1 Negative affix                  1 Present   \n\n  48A Person Marking on Adpositions 1A Consonant Inventories  \n0                   3 Pronouns only       4 Moderately large  \n1                   3 Pronouns only       4 Moderately large  \n2               2 No person marking                3 Average  \n3                   3 Pronouns only                      NaN  \n4               2 No person marking       4 Moderately large  \n\n[5 rows x 33 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lcode</th>\n      <th>lname</th>\n      <th>family</th>\n      <th>143A Order of Negative Morpheme and Verb</th>\n      <th>143F Postverbal Negative Morphemes</th>\n      <th>143G Minor morphological means of signaling negation</th>\n      <th>82A Order of Subject and Verb</th>\n      <th>143E Preverbal Negative Morphemes</th>\n      <th>83A Order of Object and Verb</th>\n      <th>85A Order of Adposition and Noun Phrase</th>\n      <th>...</th>\n      <th>19A Presence of Uncommon Consonants</th>\n      <th>3A Consonant-Vowel Ratio</th>\n      <th>8A Lateral Consonants</th>\n      <th>6A Uvular Consonants</th>\n      <th>18A Absence of Common Consonants</th>\n      <th>69A Position of Tense-Aspect Affixes</th>\n      <th>112A Negative Morphemes</th>\n      <th>107A Passive Constructions</th>\n      <th>48A Person Marking on Adpositions</th>\n      <th>1A Consonant Inventories</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>amh</td>\n      <td>Amharic</td>\n      <td>Afro-Asiatic</td>\n      <td>14 ObligDoubleNeg</td>\n      <td>2 [V-Neg]</td>\n      <td>4 None</td>\n      <td>1 SV</td>\n      <td>2 [Neg-V]</td>\n      <td>1 OV</td>\n      <td>4 No dominant order</td>\n      <td>...</td>\n      <td>1 None</td>\n      <td>4 Moderately high</td>\n      <td>2 /l/, no obstruent laterals</td>\n      <td>1 None</td>\n      <td>1 All present</td>\n      <td>4 Mixed type</td>\n      <td>6 Double negation</td>\n      <td>1 Present</td>\n      <td>3 Pronouns only</td>\n      <td>4 Moderately large</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>arz</td>\n      <td>Arabic (Egyptian)</td>\n      <td>Afro-Asiatic</td>\n      <td>15 OptDoubleNeg</td>\n      <td>2 [V-Neg]</td>\n      <td>4 None</td>\n      <td>1 SV</td>\n      <td>3 NegV&amp;[Neg-V]</td>\n      <td>2 VO</td>\n      <td>2 Prepositions</td>\n      <td>...</td>\n      <td>4 Pharyngeals</td>\n      <td>4 Moderately high</td>\n      <td>2 /l/, no obstruent laterals</td>\n      <td>4 Uvular stops and continuants</td>\n      <td>1 All present</td>\n      <td>4 Mixed type</td>\n      <td>2 Negative particle</td>\n      <td>1 Present</td>\n      <td>3 Pronouns only</td>\n      <td>4 Moderately large</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bej</td>\n      <td>Beja</td>\n      <td>Afro-Asiatic</td>\n      <td>3 [Neg-V]</td>\n      <td>4 None</td>\n      <td>4 None</td>\n      <td>1 SV</td>\n      <td>2 [Neg-V]</td>\n      <td>1 OV</td>\n      <td>1 Postpositions</td>\n      <td>...</td>\n      <td>1 None</td>\n      <td>3 Average</td>\n      <td>2 /l/, no obstruent laterals</td>\n      <td>1 None</td>\n      <td>1 All present</td>\n      <td>2 Tense-aspect suffixes</td>\n      <td>1 Negative affix</td>\n      <td>1 Present</td>\n      <td>2 No person marking</td>\n      <td>3 Average</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>heb</td>\n      <td>Hebrew (Modern)</td>\n      <td>Afro-Asiatic</td>\n      <td>1 NegV</td>\n      <td>4 None</td>\n      <td>4 None</td>\n      <td>1 SV</td>\n      <td>1 NegV</td>\n      <td>2 VO</td>\n      <td>2 Prepositions</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4 Mixed type</td>\n      <td>2 Negative particle</td>\n      <td>1 Present</td>\n      <td>3 Pronouns only</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>irk</td>\n      <td>Iraqw</td>\n      <td>Afro-Asiatic</td>\n      <td>4 [V-Neg]</td>\n      <td>2 [V-Neg]</td>\n      <td>4 None</td>\n      <td>1 SV</td>\n      <td>4 None</td>\n      <td>1 OV</td>\n      <td>2 Prepositions</td>\n      <td>...</td>\n      <td>4 Pharyngeals</td>\n      <td>5 High</td>\n      <td>4 /l/ and lateral obstruent</td>\n      <td>2 Uvular stops only</td>\n      <td>1 All present</td>\n      <td>5 No tense-aspect inflection</td>\n      <td>1 Negative affix</td>\n      <td>1 Present</td>\n      <td>2 No person marking</td>\n      <td>4 Moderately large</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 33 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest part is to extract the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df[\"family\"].to_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<bound method IndexOpsMixin.to_numpy of 0         Afro-Asiatic\n1         Afro-Asiatic\n2         Afro-Asiatic\n3         Afro-Asiatic\n4         Afro-Asiatic\n            ...       \n84    Trans-New Guinea\n85         Uto-Aztecan\n86         Uto-Aztecan\n87         Uto-Aztecan\n88         Uto-Aztecan\nName: family, Length: 89, dtype: object>\n"
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 89 families in the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to one-hot encode the 30 columns of features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a one-hot encoding function\n",
    "def onehot_encoder(input_array):\n",
    "\tunique_elements = list(set(input_array)) # the \"vocabulary\" of the array\n",
    "\toutput_array = [None]*len(input_array) # output has the same shape of input\n",
    "\tfor i in range(0, len(input_array)): # for each element of the input array:\n",
    "\t\tcurrent_element = input_array[i]\n",
    "\t\tif current_element in [\"NA\", \"NaN\"]:\n",
    "\t\t\toutput_array[i] = [0]*len(unique_elements) # create an array of 0s\n",
    "\t\telse:\n",
    "\t\t\toutput_array[i] = [0]*len(unique_elements) # create an array of 0s, then fill out the appropriate 1s\n",
    "\t\t\tfor j in range(0, len(unique_elements)):\n",
    "\t\t\t\tif current_element == unique_elements[j]:\n",
    "\t\t\t\t\toutput_array[i][j] = 1 # put a 1 corresponding to the position of the element in the dict\n",
    "\treturn(output_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_a = [\"a\", \"b\", \"NaN\", \"c\", \"NA\", \"d\", \"a\", \"b\", \"f\", \"NA\", \"c\", \"NaN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[[0, 0, 0, 1, 0, 0, 0],\n [0, 0, 1, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 1, 0],\n [0, 0, 0, 0, 0, 0, 0],\n [0, 1, 0, 0, 0, 0, 0],\n [0, 0, 0, 1, 0, 0, 0],\n [0, 0, 1, 0, 0, 0, 0],\n [0, 0, 0, 0, 1, 0, 0],\n [0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 1, 0],\n [0, 0, 0, 0, 0, 0, 0]]"
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "onehot_encoder(input_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it on a column of the df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encoded_column = onehot_encoder(df.iloc[:, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0    14 ObligDoubleNeg\n1      15 OptDoubleNeg\n2            3 [Neg-V]\n3               1 NegV\n4            4 [V-Neg]\n5               2 VNeg\n6               1 NegV\n7               1 NegV\n8    14 ObligDoubleNeg\n9            4 [V-Neg]\nName: 143A Order of Negative Morpheme and Verb, dtype: object\n"
    }
   ],
   "source": [
    "print(df.iloc[0:10, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]"
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "test_encoded_column[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears to be working; let's apply it to every column (except from first three):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_features_df = df.iloc[:, 3:].apply(onehot_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  143A Order of Negative Morpheme and Verb 143F Postverbal Negative Morphemes  \\\n0        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]                    [0, 0, 1, 0, 0]   \n1        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]                    [0, 0, 1, 0, 0]   \n2        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]                    [0, 1, 0, 0, 0]   \n3        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]                    [0, 1, 0, 0, 0]   \n4        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]                    [0, 0, 1, 0, 0]   \n\n  143G Minor morphological means of signaling negation  \\\n0                                          [0, 1, 0]     \n1                                          [0, 1, 0]     \n2                                          [0, 1, 0]     \n3                                          [0, 1, 0]     \n4                                          [0, 1, 0]     \n\n  82A Order of Subject and Verb 143E Preverbal Negative Morphemes  \\\n0                     [0, 1, 0]                   [0, 0, 0, 1, 0]   \n1                     [0, 1, 0]                   [0, 0, 1, 0, 0]   \n2                     [0, 1, 0]                   [0, 0, 0, 1, 0]   \n3                     [0, 1, 0]                   [0, 0, 0, 0, 1]   \n4                     [0, 1, 0]                   [0, 1, 0, 0, 0]   \n\n  83A Order of Object and Verb 85A Order of Adposition and Noun Phrase  \\\n0                 [0, 0, 1, 0]                         [0, 0, 0, 1, 0]   \n1                 [0, 1, 0, 0]                         [0, 0, 1, 0, 0]   \n2                 [0, 0, 1, 0]                         [0, 1, 0, 0, 0]   \n3                 [0, 1, 0, 0]                         [0, 0, 1, 0, 0]   \n4                 [0, 0, 1, 0]                         [0, 0, 1, 0, 0]   \n\n  86A Order of Genitive and Noun 88A Order of Demonstrative and Noun  \\\n0                   [0, 0, 1, 0]                  [0, 1, 0, 0, 0, 0]   \n1                   [0, 1, 0, 0]                  [0, 0, 1, 0, 0, 0]   \n2                   [0, 0, 1, 0]                  [0, 0, 0, 0, 1, 0]   \n3                   [0, 1, 0, 0]                  [0, 0, 1, 0, 0, 0]   \n4                   [0, 1, 0, 0]                  [0, 0, 1, 0, 0, 0]   \n\n  87A Order of Adjective and Noun  ... 19A Presence of Uncommon Consonants  \\\n0                    [0, 0, 0, 1]  ...                  [0, 1, 0, 0, 0, 0]   \n1                    [0, 1, 0, 0]  ...                  [0, 0, 0, 0, 1, 0]   \n2                    [0, 0, 1, 0]  ...                  [0, 1, 0, 0, 0, 0]   \n3                    [0, 1, 0, 0]  ...                  [0, 0, 0, 0, 0, 0]   \n4                    [0, 1, 0, 0]  ...                  [0, 0, 0, 0, 1, 0]   \n\n  3A Consonant-Vowel Ratio 8A Lateral Consonants 6A Uvular Consonants  \\\n0       [0, 0, 0, 0, 0, 1]    [0, 0, 0, 0, 1, 0]      [0, 0, 0, 1, 0]   \n1       [0, 0, 0, 0, 0, 1]    [0, 0, 0, 0, 1, 0]      [0, 0, 1, 0, 0]   \n2       [0, 0, 0, 1, 0, 0]    [0, 0, 0, 0, 1, 0]      [0, 0, 0, 1, 0]   \n3       [0, 0, 0, 0, 0, 0]    [0, 0, 0, 0, 0, 0]      [0, 0, 0, 0, 0]   \n4       [0, 0, 0, 0, 1, 0]    [0, 0, 0, 1, 0, 0]      [0, 0, 0, 0, 1]   \n\n  18A Absence of Common Consonants 69A Position of Tense-Aspect Affixes  \\\n0                     [0, 0, 1, 0]                   [0, 0, 0, 0, 0, 1]   \n1                     [0, 0, 1, 0]                   [0, 0, 0, 0, 0, 1]   \n2                     [0, 0, 1, 0]                   [0, 0, 0, 0, 1, 0]   \n3                     [0, 0, 0, 0]                   [0, 0, 0, 0, 0, 1]   \n4                     [0, 0, 1, 0]                   [0, 1, 0, 0, 0, 0]   \n\n  112A Negative Morphemes 107A Passive Constructions  \\\n0      [0, 1, 0, 0, 0, 0]                  [0, 0, 1]   \n1      [0, 0, 1, 0, 0, 0]                  [0, 0, 1]   \n2      [0, 0, 0, 0, 1, 0]                  [0, 0, 1]   \n3      [0, 0, 1, 0, 0, 0]                  [0, 0, 1]   \n4      [0, 0, 0, 0, 1, 0]                  [0, 0, 1]   \n\n  48A Person Marking on Adpositions 1A Consonant Inventories  \n0                   [0, 0, 0, 1, 0]       [0, 0, 0, 0, 1, 0]  \n1                   [0, 0, 0, 1, 0]       [0, 0, 0, 0, 1, 0]  \n2                   [0, 0, 1, 0, 0]       [0, 0, 1, 0, 0, 0]  \n3                   [0, 0, 0, 1, 0]       [0, 0, 0, 0, 0, 0]  \n4                   [0, 0, 1, 0, 0]       [0, 0, 0, 0, 1, 0]  \n\n[5 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>143A Order of Negative Morpheme and Verb</th>\n      <th>143F Postverbal Negative Morphemes</th>\n      <th>143G Minor morphological means of signaling negation</th>\n      <th>82A Order of Subject and Verb</th>\n      <th>143E Preverbal Negative Morphemes</th>\n      <th>83A Order of Object and Verb</th>\n      <th>85A Order of Adposition and Noun Phrase</th>\n      <th>86A Order of Genitive and Noun</th>\n      <th>88A Order of Demonstrative and Noun</th>\n      <th>87A Order of Adjective and Noun</th>\n      <th>...</th>\n      <th>19A Presence of Uncommon Consonants</th>\n      <th>3A Consonant-Vowel Ratio</th>\n      <th>8A Lateral Consonants</th>\n      <th>6A Uvular Consonants</th>\n      <th>18A Absence of Common Consonants</th>\n      <th>69A Position of Tense-Aspect Affixes</th>\n      <th>112A Negative Morphemes</th>\n      <th>107A Passive Constructions</th>\n      <th>48A Person Marking on Adpositions</th>\n      <th>1A Consonant Inventories</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n      <td>[0, 0, 1, 0, 0]</td>\n      <td>[0, 1, 0]</td>\n      <td>[0, 1, 0]</td>\n      <td>[0, 0, 0, 1, 0]</td>\n      <td>[0, 0, 1, 0]</td>\n      <td>[0, 0, 0, 1, 0]</td>\n      <td>[0, 0, 1, 0]</td>\n      <td>[0, 1, 0, 0, 0, 0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>...</td>\n      <td>[0, 1, 0, 0, 0, 0]</td>\n      <td>[0, 0, 0, 0, 0, 1]</td>\n      <td>[0, 0, 0, 0, 1, 0]</td>\n      <td>[0, 0, 0, 1, 0]</td>\n      <td>[0, 0, 1, 0]</td>\n      <td>[0, 0, 0, 0, 0, 1]</td>\n      <td>[0, 1, 0, 0, 0, 0]</td>\n      <td>[0, 0, 1]</td>\n      <td>[0, 0, 0, 1, 0]</td>\n      <td>[0, 0, 0, 0, 1, 0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n      <td>[0, 0, 1, 0, 0]</td>\n      <td>[0, 1, 0]</td>\n      <td>[0, 1, 0]</td>\n      <td>[0, 0, 1, 0, 0]</td>\n      <td>[0, 1, 0, 0]</td>\n      <td>[0, 0, 1, 0, 0]</td>\n      <td>[0, 1, 0, 0]</td>\n      <td>[0, 0, 1, 0, 0, 0]</td>\n      <td>[0, 1, 0, 0]</td>\n      <td>...</td>\n      <td>[0, 0, 0, 0, 1, 0]</td>\n      <td>[0, 0, 0, 0, 0, 1]</td>\n      <td>[0, 0, 0, 0, 1, 0]</td>\n      <td>[0, 0, 1, 0, 0]</td>\n      <td>[0, 0, 1, 0]</td>\n      <td>[0, 0, 0, 0, 0, 1]</td>\n      <td>[0, 0, 1, 0, 0, 0]</td>\n      <td>[0, 0, 1]</td>\n      <td>[0, 0, 0, 1, 0]</td>\n      <td>[0, 0, 0, 0, 1, 0]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n      <td>[0, 1, 0, 0, 0]</td>\n      <td>[0, 1, 0]</td>\n      <td>[0, 1, 0]</td>\n      <td>[0, 0, 0, 1, 0]</td>\n      <td>[0, 0, 1, 0]</td>\n      <td>[0, 1, 0, 0, 0]</td>\n      <td>[0, 0, 1, 0]</td>\n      <td>[0, 0, 0, 0, 1, 0]</td>\n      <td>[0, 0, 1, 0]</td>\n      <td>...</td>\n      <td>[0, 1, 0, 0, 0, 0]</td>\n      <td>[0, 0, 0, 1, 0, 0]</td>\n      <td>[0, 0, 0, 0, 1, 0]</td>\n      <td>[0, 0, 0, 1, 0]</td>\n      <td>[0, 0, 1, 0]</td>\n      <td>[0, 0, 0, 0, 1, 0]</td>\n      <td>[0, 0, 0, 0, 1, 0]</td>\n      <td>[0, 0, 1]</td>\n      <td>[0, 0, 1, 0, 0]</td>\n      <td>[0, 0, 1, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n      <td>[0, 1, 0, 0, 0]</td>\n      <td>[0, 1, 0]</td>\n      <td>[0, 1, 0]</td>\n      <td>[0, 0, 0, 0, 1]</td>\n      <td>[0, 1, 0, 0]</td>\n      <td>[0, 0, 1, 0, 0]</td>\n      <td>[0, 1, 0, 0]</td>\n      <td>[0, 0, 1, 0, 0, 0]</td>\n      <td>[0, 1, 0, 0]</td>\n      <td>...</td>\n      <td>[0, 0, 0, 0, 0, 0]</td>\n      <td>[0, 0, 0, 0, 0, 0]</td>\n      <td>[0, 0, 0, 0, 0, 0]</td>\n      <td>[0, 0, 0, 0, 0]</td>\n      <td>[0, 0, 0, 0]</td>\n      <td>[0, 0, 0, 0, 0, 1]</td>\n      <td>[0, 0, 1, 0, 0, 0]</td>\n      <td>[0, 0, 1]</td>\n      <td>[0, 0, 0, 1, 0]</td>\n      <td>[0, 0, 0, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n      <td>[0, 0, 1, 0, 0]</td>\n      <td>[0, 1, 0]</td>\n      <td>[0, 1, 0]</td>\n      <td>[0, 1, 0, 0, 0]</td>\n      <td>[0, 0, 1, 0]</td>\n      <td>[0, 0, 1, 0, 0]</td>\n      <td>[0, 1, 0, 0]</td>\n      <td>[0, 0, 1, 0, 0, 0]</td>\n      <td>[0, 1, 0, 0]</td>\n      <td>...</td>\n      <td>[0, 0, 0, 0, 1, 0]</td>\n      <td>[0, 0, 0, 0, 1, 0]</td>\n      <td>[0, 0, 0, 1, 0, 0]</td>\n      <td>[0, 0, 0, 0, 1]</td>\n      <td>[0, 0, 1, 0]</td>\n      <td>[0, 1, 0, 0, 0, 0]</td>\n      <td>[0, 0, 0, 0, 1, 0]</td>\n      <td>[0, 0, 1]</td>\n      <td>[0, 0, 1, 0, 0]</td>\n      <td>[0, 0, 0, 0, 1, 0]</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 30 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "encoded_features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how we flatten each row into a numpy array which is the concatenation of all features of the row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_features = np.array([element for feature in encoded_features_df.iloc[0, :] for element in feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0\n 0 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0\n 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1\n 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0]\n168\n"
    }
   ],
   "source": [
    "print(flat_features)\n",
    "print(len(flat_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we do this for every row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.empty([89, 168]) # initialize empty matrix with appropriate dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(0, features.shape[0]):\n",
    "    features[row] = np.array([element for feature in encoded_features_df.iloc[row, :] for element in feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0., 1., 0., ..., 0., 1., 0.],\n       [0., 0., 0., ..., 0., 1., 0.],\n       [0., 0., 1., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 1., 0., 0.]])"
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can put everything together in a function called `encode()` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(path_to_file):\n",
    "    # read the data\n",
    "    df = pd.read_csv(path_to_file, sep = \"\\t\")\n",
    "\n",
    "    # labels\n",
    "    labels = df[\"family\"].to_numpy\n",
    "\n",
    "    # features\n",
    "    encoded_features_df = df.iloc[:, 3:].apply(onehot_encoder)\n",
    "    features = np.empty([89, 168])\n",
    "    for row in range(0, features.shape[0]):\n",
    "        features[row] = np.array([element for feature in encoded_features_df.iloc[row, :] for element in feature])\n",
    "\n",
    "    return(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = encode(\"data/wals-train.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0., 1., 0., ..., 0., 1., 0.],\n       [0., 0., 0., ..., 0., 1., 0.],\n       [0., 0., 1., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 1., 0., 0.]])"
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<bound method IndexOpsMixin.to_numpy of 0         Afro-Asiatic\n1         Afro-Asiatic\n2         Afro-Asiatic\n3         Afro-Asiatic\n4         Afro-Asiatic\n            ...       \n84    Trans-New Guinea\n85         Uto-Aztecan\n86         Uto-Aztecan\n87         Uto-Aztecan\n88         Uto-Aztecan\nName: family, Length: 89, dtype: object>"
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitcf06a54604fa462da990d50073f42498",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}